# Deep-Learning-Paper-Study

<h3>Starting from 2021..<br></h3>

:book: Reading...

>  Deep Residual Learning for Image Recognition

>  Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors

> Adversarial examples are not bugs, they are features

> Neural tangent kernel: Convergence and generalization in neural networks

> DEEP NEURAL NETWORKS AS GAUSSIAN PROCESSES

> Dropout: A Simple Way to Prevent Neural Networks from Overfitting

> Batch Normalization: Accelerating Deep Network Training by Reducing Internal
> Covariate Shift

:books: Papers read

* Detection

> Rich feature hierarchies for accurate object detection and semantic segmentation

> Fast R-CNN

> YOLO

> SSD

* GAN

>  Wassertein GAN

> Cycle GAN

> <b><span style="color: white; background-color: lightblue">infoGAN</span></b>

* Domain Adaptation

> <b><span style="color: white; background-color: lightblue">Normalized Wasserstein for Mixture Distributions with Applications in Adversarial Learning and Domain Adaptation
> </span></b>

> <b><span style="color: white; background-color: lightblue">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks Jun-Yan</span></b>

* Adversarial

> Adversarial Examples Improve Image Recognition

> Making an Invisibility Cloak: Real World Adversarial Attacks on Object Detectors

> DeepFool: a simple and accurate method to fool deep neural networks

* NTK



* Etc...